{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "import unittest\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "!wget -O ./shape_predictor_68_face_landmarks.dat \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat\"\n",
    "dlibshape_path ='./shape_predictor_68_face_landmarks.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontalface_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def detect_face(image_url):\n",
    "  try:\n",
    "    url_response = urllib.request.urlopen(image_url)\n",
    "    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(img_array, -1)\n",
    "  except Exception as e:\n",
    "    return \"Please check the URL and try again!\"\n",
    "    \n",
    "  rects = frontalface_detector(image, 1)\n",
    "  \n",
    "  if len(rects) < 1:\n",
    "    return \"No Face Detected\"\n",
    "  \n",
    "  for (i, rect) in enumerate(rects):\n",
    "    (x, y, w, h) = rect_to_bb(rect)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "  plt.imshow(image, interpolation='nearest')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face(input('Enter the URL of the image: '));  # run cell and when prompted, input a URL of an img and press 'enter'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontalface_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image_url):\n",
    "  try:\n",
    "    url_response = urllib.request.urlopen(image_url)\n",
    "    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(img_array, -1)\n",
    "    \n",
    "  except Exception as e:\n",
    "    print (\"Please check the URL and try again!\")\n",
    "    return None,None\n",
    "  \n",
    "  faces = frontalface_detector(image, 1)\n",
    "  if len(faces):\n",
    "    landmarks = [(p.x, p.y) for p in landmark_predictor(image, faces[0]).parts()]\n",
    "  else:\n",
    "    return None,None\n",
    "  \n",
    "  return image,landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_landmarks(image,face_landmarks):\n",
    "  radius = -1\n",
    "  circle_thickness = 5\n",
    "  image_copy = image.copy()\n",
    "  for (x, y) in face_landmarks:\n",
    "    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n",
    "  plt.imshow(image_copy, interpolation='nearest')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,landmarks= get_landmarks(input(\"Enter the URL of the image: \")) #url\n",
    "if landmarks:\n",
    "  plot_image_landmarks(image,landmarks)\n",
    "else:\n",
    "  print (\"No Landmarks Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_indices(landmarks, i_index): \n",
    "  \n",
    "  plt.scatter(x=[landmarks[i][0] for i in range(len(landmarks)//2, len(landmarks))], \n",
    "              y=[-landmarks[i][1] for i in range(len(landmarks)//2, len(landmarks))], s=50, alpha=.5, color='blue', label='second half of indices') \n",
    "\n",
    "  plt.scatter(x=[landmarks[i][0] for i in range(len(landmarks)//2)], \n",
    "              y=[-landmarks[i][1] for i in range(len(landmarks)//2)], color='red', alpha=.5, label='first half of indices')\n",
    "\n",
    "  x = landmarks[i_index][0]\n",
    "  y = -landmarks[i_index][1]\n",
    "  plt.scatter(x=x, y=y, \n",
    "             color='purple', s=100, marker='x', label='feature at index %d'%i_index)\n",
    "  \n",
    "  plt.scatter(x, y, color='red', alpha=.5, label='selected indices')\n",
    "\n",
    "  plt.axis('off');\n",
    "  plt.legend(bbox_to_anchor=[1,1]);\n",
    "  plt.title('Visualizing the features we\\'ve extracted from this image',y =1.2); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_index = 30\n",
    "show_indices(landmarks, show_index)\n",
    "np.array(landmarks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_indices = {'eyes':(36,47),\n",
    "                    \"nose\":(27,35),\n",
    "                    \"mouth\":(48,67),\n",
    "                    \"jawline\":(0,17),\n",
    "                    \"eyebrow\":(18,27)}\n",
    "\n",
    "\n",
    "print(landmark_indices[\"eyes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_points = np.array([36,47])\n",
    "selected_landmarks = landmarks[eye_points[0]:eye_points[1]+1]\n",
    "print(selected_landmarks)\n",
    "plot_image_landmarks(image,selected_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACIAL_LANDMARKS_IDXS = {\"EYES\":(36,47),\n",
    "                         \"NOSE\":(27,35),\n",
    "                         \"MOUTH\":(48,67),\n",
    "                        \"JAWLINE\":(0,17),\n",
    "                        \"EYEBROWS\":(18,27)}\n",
    "\n",
    "for key,value in FACIAL_LANDMARKS_IDXS.items():\n",
    "  print (key,\"DETECTION\")\n",
    "  selected_landmarks = landmarks[value[0]:value[1]+1]\n",
    "  plot_image_landmarks(image, selected_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1,p2):\n",
    "  distance =  math.sqrt((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(image1_path, image2_path, plt_flag):\n",
    "  \n",
    "  image1,image1_landmarks = get_landmarks(image1_path)\n",
    "  image2,image2_landmarks = get_landmarks(image2_path)\n",
    "  \n",
    "  if plt_flag:\n",
    "    plt.imshow(image1, interpolation='nearest')\n",
    "    plt.title(\"Image1\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(image2, interpolation='nearest')\n",
    "    plt.title(\"Image2\")\n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "  pairs_distance = [(37,41),(38,40),(43,47),(44,46)]\n",
    "  \n",
    "  e_sum1 = 0\n",
    "  e_sum2 = 0\n",
    "  threshold_value = 10\n",
    "  for pair in pairs_distance:\n",
    "    \n",
    "    e_sum1 = e_sum1 + euclidean_distance(image1_landmarks[pair[0]],\n",
    "                                         image1_landmarks[pair[1]])\n",
    "    e_sum2 = e_sum2 + euclidean_distance(image2_landmarks[pair[0]],\n",
    "                                         image2_landmarks[pair[1]])\n",
    "  print (e_sum1,e_sum2)\n",
    "  \n",
    "  e_difference = e_sum1 - e_sum2\n",
    "  print (e_difference)\n",
    "  if int(e_difference) == 0:\n",
    "    return (\"Both images have eyes open or closed\")\n",
    "  \n",
    "  if abs(e_difference) >= threshold_value:\n",
    "     \n",
    "    if e_difference > 0:\n",
    "        return (\"Image1 : Eyes Open, Image2 : Eyes Close\")\n",
    "    else:\n",
    "        return (\"Image1 : Eyes Close, Image2 : Eyes Open\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
